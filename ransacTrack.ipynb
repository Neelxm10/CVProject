{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from ransac import ransac\n",
    "from imageProcessor import imageProcessor\n",
    "# Import necessary modules for 3D plotting\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create lists to store coordinates\n",
    "\n",
    "\n",
    "filename = \"videos/coin.mov\"\n",
    "capture = cv.VideoCapture(filename)\n",
    "framecnt = 0\n",
    "\n",
    "if not os.path.exists('Frame_Dump'):\n",
    "    os.mkdir('Frame_Dump')\n",
    "else:\n",
    "    print(\"Directory already exists, proceeding with overwriting directory\\n\")\n",
    "\n",
    "frame_count_list = []\n",
    "center_xlist = []  \n",
    "center_ylist = []\n",
    "plt.ion()  # Turn on interactive mode\n",
    "\n",
    "try:\n",
    "    while capture.isOpened():\n",
    "        state, frame = capture.read()\n",
    "        if state:\n",
    "            framecnt += 1\n",
    "            centerX, centerY = imageProcessor(frame, framecnt)\n",
    "\n",
    "            # If center x-coordinate is found, append it to the list\n",
    "            if centerX and centerY is not None:\n",
    "                frame_count_list.append(framecnt)\n",
    "                center_xlist.append(centerX)\n",
    "                center_ylist.append(centerY)\n",
    "                # Plot the center coordinates with respect to frame count\n",
    "                plt.clf()  # Clear the previous plot\n",
    "                plt.plot(frame_count_list, center_xlist, label='Center X Coordinate', marker='o', linestyle='-')\n",
    "                plt.plot(frame_count_list, center_ylist, label='Center Y Coordinate', marker='o', linestyle='-')\n",
    "                plt.xlabel('Frame Count')\n",
    "                plt.ylabel('Center Position')\n",
    "                plt.legend()\n",
    "                plt.title('Center Position over Frame Count')\n",
    "                plt.draw()\n",
    "                plt.pause(0.1)  # Adjust the pause duration as needed\n",
    "\n",
    "            print('FrameCount:' + str(framecnt) + '\\n')\n",
    "        else:\n",
    "            print(\"No remaining frames to process\\n\")\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted by user\")\n",
    "\n",
    "finally:\n",
    "    plt.ioff()  # Turn off interactive mode\n",
    "    capture.release()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The video is broken up into frames, and each individual frame is passed into the python function imageProcessor, defined below. The function below performs morphological operations such as binary masks, dilation and erosion, and finally edge detection. The edge points detected are then passed into the RANSAC algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from ransac import ransac\n",
    "\n",
    "def imageProcessor(img, framecnt):\n",
    "#Currently converts image to HSV to test functionality. We can build algorithm here.\n",
    "\n",
    "    \n",
    "    #show the original image\n",
    "    #cv.imshow('video reader', img)\n",
    "\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "# Define the ROI parameters\n",
    "    top_margin = height // 8  # 1/8th of the height from the top\n",
    "    bottom_margin = height // 8  # 1/8th of the height from the bottom\n",
    "    \n",
    "\n",
    "# Applying ROI mask\n",
    "    roi = img[top_margin:height - bottom_margin]\n",
    "    avgkernel = np.ones((8,8),np.float32)/(64)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "    gray_img = cv.cvtColor(roi, cv.COLOR_BGR2GRAY)\n",
    "    #cv.imshow('region of interest', gray_img)\n",
    "# Ensure that the image is of type CV_8UC1\n",
    "    if gray_img.dtype != np.uint8:\n",
    "        gray_img = cv.convertScaleAbs(gray_img)\n",
    "\n",
    "#Apply Otsu's thresholding\n",
    "    ret, mask = cv.threshold(gray_img, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "  \n",
    "#create structuring element and use it to perform opening mask\n",
    "    disc = cv.getStructuringElement(cv.MORPH_RECT, (5,5))\n",
    "    #cv.imshow('mask', mask)  \n",
    "\n",
    "#dilate, erode, and dilate again.\n",
    "    eroded_mask = cv.erode(mask, disc,1)\n",
    "    dilated_mask = cv.dilate(eroded_mask, disc, 5)\n",
    "    #cv.imshow('mask', dilated_mask)\n",
    "    \n",
    "\n",
    "    edges = cv.Canny(dilated_mask, 0, 220)\n",
    "    #cv.imshow('edges', edges)\n",
    "\n",
    "    Circle = ransac(edges,350, 50,10, framecnt, roi)\n",
    "\n",
    "    cv.waitKey(200)\n",
    "    if Circle is not None:\n",
    "        return Circle[0]  # Return only the center coordinates (x, y)\n",
    "    else:\n",
    "        return 0,0  # Return None when no circle is found\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RANSAC algorithm below takes the arguments in terms of a radius threshold in pixels, the edge points, the max number of iterations per frame, the minimum number of inliers, and the original image. The algorithm uses the Hough Transform of a circle by randomly sampling three edge points, drawing circles around each point in parameter space, and from there, the intersections between the circles in parameter space are stored in an accumulator array. Non-maximal suppression is applied to find the most dominant circle intersection points in parameter space. The intersection point with the most amount of votes in the accumulator array, is then considered a circle center in image space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def ransac(img, threshold, max_iterations, min_inline, framecnt, orig):\n",
    "    #Collect number of edge points\n",
    "    num_points = np.column_stack(np.where(img > 0))\n",
    "\n",
    "    #check to ensure there are edge points present in the image.\n",
    "    if len(num_points) == 0:\n",
    "        print(\"No edge points found in the binary image.\")\n",
    "        return None\n",
    "\n",
    "    #preallocate memory for variables such as best circle, max_inliers, and the accumulator array.\n",
    "    accumulator = np.zeros_like(img, dtype=int)\n",
    "    best_circle = None\n",
    "    max_inliers = 0\n",
    "\n",
    "    #Iterate through the desired number of RANSAC iterations\n",
    "    for i in range(max_iterations):\n",
    "        #randomly sample x-number of points. Best number of points is related to the accuracy of the RANSAC.\n",
    "        sample_index = np.random.choice(len(num_points), size=3)\n",
    "        sample_points = num_points[sample_index]\n",
    "\n",
    "        #append the randomly sampled points\n",
    "        xi, yi = sample_points[:, 1], sample_points[:, 0]\n",
    "\n",
    "        #create a circle in parameter space around the sampled points.\n",
    "        c = np.array([np.mean(xi), np.mean(yi)])\n",
    "        r = np.mean(np.sqrt((xi - c[0]) ** 2 + (yi - c[1]) ** 2))\n",
    "\n",
    "        #ensure that the sampled circles are within image bounds.\n",
    "        if c[0] < img.shape[1] and  c[1] < img.shape[0] and 0 < r < min(img.shape[0], img.shape[1]) / 2:\n",
    "            #in image space, a and b are the center of the circle. In parameter space, it will be the circular edge coordinates with distinct sample points.\n",
    "            th = np.arange(0, 2 * np.pi, 0.01)\n",
    "            a = c[0] + (r * np.cos(th))\n",
    "            b = c[1] + (r * np.sin(th))\n",
    "\n",
    "            #ensures that the generated circle coordinates are converted to integers, and any potential coordinates close to the image boundaries are clipped within a safe margin \n",
    "            #to prevent the circle from going outside the valid image region. \n",
    "            #This is crucial for subsequent operations, such as updating the accumulator with votes for the circle in the Hough space.\n",
    "            margin = 5  # Adjust this margin as required (found experimentally)\n",
    "            a_idx = np.clip(a.astype(int), 0 + margin, img.shape[1] - 1 - margin)\n",
    "            b_idx = np.clip(b.astype(int), 0 + margin, img.shape[0] - 1 - margin)\n",
    "            #Increment the accumulator at the circle coordinates\n",
    "            accumulator[b_idx, a_idx] += 1\n",
    "\n",
    "            # Non-maximal suppression: enhance local maxima in accumulator array (dilation), and  apply logical mask to accumulator array to only retain local maxima. \n",
    "            accumulator = cv.convertScaleAbs(accumulator)\n",
    "            local_max = cv.dilate(accumulator, np.ones((3, 3)), iterations=1)\n",
    "            lmax_mask = (local_max == accumulator)\n",
    "            accumulator *= lmax_mask\n",
    "    \n",
    "    #Iterate through the coordinates of the local maxima in the parameter space (max_coords). \n",
    "    for max_coords in np.argwhere(accumulator > 0):\n",
    "        \n",
    "        #The radius and center of the circle are calculated based on the relationship between the sampled points (xi and yi) and the coordinates of the local maxima. \n",
    "        radius = np.mean(np.sqrt((xi - max_coords[1]) ** 2 + (yi - max_coords[0]) ** 2))\n",
    "        center = (max_coords[1], max_coords[0])\n",
    "        \n",
    "        #Generate the coordinates of the circle and clip them to ensure they are within the image bounds\n",
    "        th = np.arange(0, 2 * np.pi, 0.01)\n",
    "        x_circle = (center[0] + radius * np.cos(th)).astype(int)\n",
    "        y_circle = (center[1] + radius * np.sin(th)).astype(int)\n",
    "\n",
    "        x_circle = np.clip(x_circle, 0, img.shape[1] - 1)\n",
    "        y_circle = np.clip(y_circle, 0, img.shape[0] - 1)\n",
    "\n",
    "    #Count the number of inliers (edge points inside the circle)\n",
    "        inliers = np.sum(img[y_circle, x_circle] > 0)\n",
    "    #if the circle meets the criteria for a valid circle (minimum inliers, radius within threshold, and more inliers than the current best),\n",
    "    #update the best circle if needed\n",
    "        if inliers >= min_inline and radius <= threshold and inliers > max_inliers:\n",
    "            #print(f\"Found Circle with radius {radius} px and center {center}\")\n",
    "            best_circle = (center, radius)\n",
    "            max_inliers = inliers\n",
    "\n",
    "    #if there is a best circle detected that satisfies all aformentioned criteria, visualize it and save it as an image. \n",
    "    if best_circle is not None:\n",
    "        # Visualize the best circle\n",
    "        circ = orig.copy()\n",
    "        cv.circle(circ, best_circle[0], int(best_circle[1]), [0, 255, 0], 2)\n",
    "        cv.circle(circ, best_circle[0], 5, [0, 0, 255], -1)\n",
    "        cv.putText(circ, f'Center: ({best_circle[0][0]}, {best_circle[0][1]})', (10, 30), cv.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                   (0, 255, 255), 2)\n",
    "\n",
    "        cv.imshow('Best Circle', circ)\n",
    "        cv.imwrite(f\"Frame_Dump/Best_Circle_Detected{framecnt}.png\", circ)\n",
    "        cv.waitKey(10)\n",
    "        \n",
    "    else:\n",
    "        print(\"No circles found\")\n",
    "\n",
    "    return best_circle"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
